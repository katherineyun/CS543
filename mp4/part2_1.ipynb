{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "part2.1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2uohksRc8R6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Mounting your Google Drive is optional, and you could also simply copy and\n",
        "# upload the data to your colab instance. This manula upload is also easy to do, \n",
        "# but you will have to figure out how to do it.\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLFBEMfVdHId",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.chdir(\"/content/\")\n",
        "# if not os.path.exists(\"/content/gdrive/My Drive/CS_543_MP4\"):\n",
        "#     os.makedirs(\"/content/gdrive/My Drive/CS_543_MP4\")\n",
        "\n",
        "# from google.colab import files\n",
        "# uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJhWxMTBj5qU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip data.zip -d data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "geohpotit_Ek"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UzpXeiVddIdi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import glob\n",
        "import os\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from tqdm.notebook import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, average_precision_score\n",
        "\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils import data\n",
        "from torchvision.transforms import ToTensor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTlJmzl7dR4_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DATASET_PATH = 'data/data/sbd/'\n",
        "\n",
        "class SegmentationDataset(data.Dataset):\n",
        "    \"\"\"\n",
        "    Data loader for the Segmentation Dataset. If data loading is a bottleneck, \n",
        "    you may want to optimize this in for faster training. Possibilities include\n",
        "    pre-loading all images and annotations into memory before training, so as \n",
        "    to limit delays due to disk reads.\n",
        "    \"\"\"\n",
        "    def __init__(self, split=\"train\", data_dir=DATASET_PATH):\n",
        "        assert(split in [\"train\", \"val\", \"test\"])\n",
        "        self.img_dir = os.path.join(data_dir, split)\n",
        "        self.classes = []\n",
        "        with open(os.path.join(data_dir, 'classes.txt'), 'r') as f:\n",
        "          for l in f:\n",
        "            self.classes.append(l.rstrip())\n",
        "        self.n_classes = len(self.classes)\n",
        "        self.split = split\n",
        "        self.data = glob.glob(self.img_dir + '/*.jpg') \n",
        "        self.data = [os.path.splitext(l)[0] for l in self.data]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img = Image.open(self.data[index] + '.jpg')\n",
        "        gt = Image.open(self.data[index] + '.png')\n",
        "        \n",
        "        img = ToTensor()(img)\n",
        "        gt = torch.LongTensor(np.asarray(gt)).unsqueeze(0)\n",
        "        return img, gt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6Dtn7yudjC8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def segmentation_eval(gts, preds, classes, plot_file_name):\n",
        "    \"\"\"\n",
        "    @param    gts               numpy.ndarray   ground truth labels\n",
        "    @param    preds             numpy.ndarray   predicted labels\n",
        "    @param    classes           string          class names\n",
        "    @param    plot_file_name    string          plot file names\n",
        "    \"\"\"\n",
        "    ious, counts = compute_confusion_matrix(gts, preds)\n",
        "    aps = compute_ap(gts, preds)\n",
        "    plot_results(counts, ious, aps, classes, plot_file_name)\n",
        "    for i in range(len(classes)):\n",
        "        print('{:>20s}: AP: {:0.2f}, IoU: {:0.2f}'.format(classes[i], aps[i], ious[i]))\n",
        "    print('{:>20s}: AP: {:0.2f}, IoU: {:0.2f}'.format('mean', np.mean(aps), np.mean(ious)))\n",
        "    return aps, ious\n",
        "\n",
        "def plot_results(counts, ious, aps, classes, file_name):\n",
        "    fig, ax = plt.subplots(1,1)\n",
        "    conf = counts / np.sum(counts, 1, keepdims=True)\n",
        "    conf = np.concatenate([conf, np.array(aps).reshape(-1,1), \n",
        "                           np.array(ious).reshape(-1,1)], 1)\n",
        "    conf = conf * 100.\n",
        "    sns.heatmap(conf, annot=True, ax=ax, fmt='3.0f') \n",
        "    arts = [] \n",
        "    # labels, title and ticks\n",
        "    _ = ax.set_xlabel('Predicted labels')\n",
        "    arts.append(_)\n",
        "    _ = ax.set_ylabel('True labels')\n",
        "    arts.append(_)\n",
        "    _ = ax.set_title('Confusion Matrix, mAP: {:5.1f}, mIoU: {:5.1f}'.format(\n",
        "      np.mean(aps)*100., np.mean(ious)*100.))\n",
        "    arts.append(_)\n",
        "    _ = ax.xaxis.set_ticklabels(classes + ['AP', 'IoU'], rotation=90)\n",
        "    arts.append(_)\n",
        "    _ = ax.yaxis.set_ticklabels(classes, rotation=0)\n",
        "    arts.append(_)\n",
        "    fig.savefig(file_name, bbox_inches='tight')\n",
        "\n",
        "def compute_ap(gts, preds):\n",
        "    aps = []\n",
        "    for i in range(preds.shape[1]):\n",
        "      ap, prec, rec = calc_pr(gts == i, preds[:,i:i+1,:,:])\n",
        "      aps.append(ap)\n",
        "    return aps\n",
        "\n",
        "def calc_pr(gt, out, wt=None):\n",
        "    gt = gt.astype(np.float64).reshape((-1,1))\n",
        "    out = out.astype(np.float64).reshape((-1,1))\n",
        "\n",
        "    tog = np.concatenate([gt, out], axis=1)*1.\n",
        "    ind = np.argsort(tog[:,1], axis=0)[::-1]\n",
        "    tog = tog[ind,:]\n",
        "    cumsumsortgt = np.cumsum(tog[:,0])\n",
        "    cumsumsortwt = np.cumsum(tog[:,0]-tog[:,0]+1)\n",
        "    prec = cumsumsortgt / cumsumsortwt\n",
        "    rec = cumsumsortgt / np.sum(tog[:,0])\n",
        "    ap = voc_ap(rec, prec)\n",
        "    return ap, rec, prec\n",
        "\n",
        "def voc_ap(rec, prec):\n",
        "    rec = rec.reshape((-1,1))\n",
        "    prec = prec.reshape((-1,1))\n",
        "    z = np.zeros((1,1)) \n",
        "    o = np.ones((1,1))\n",
        "    mrec = np.vstack((z, rec, o))\n",
        "    mpre = np.vstack((z, prec, z))\n",
        "\n",
        "    mpre = np.maximum.accumulate(mpre[::-1])[::-1]\n",
        "    I = np.where(mrec[1:] != mrec[0:-1])[0]+1;\n",
        "    ap = np.sum((mrec[I] - mrec[I-1])*mpre[I])\n",
        "    return ap\n",
        "\n",
        "def compute_confusion_matrix(gts, preds):\n",
        "    preds_cls = np.argmax(preds, 1)\n",
        "    gts = gts[:,0]\n",
        "    #print(gts.shape, preds.shape)\n",
        "    conf = confusion_matrix(gts.ravel(), preds_cls.ravel())\n",
        "    inter = np.diag(conf)\n",
        "    union = np.sum(conf, 0) + np.sum(conf, 1) - np.diag(conf)\n",
        "    union = np.maximum(union, 1)\n",
        "    return inter / union, conf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6XlgBxwjCaa4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ##########\n",
        "# #TODO: design your own network here. The expectation is to write from scratch. But it's okay to get some inspiration \n",
        "# #from conference paper. The bottom line is that you will not just copy code from other repo\n",
        "# ##########\n",
        "\n",
        "# import torch.nn as nn\n",
        "# import torch.nn.functional as F\n",
        "# def get_upsampling_weight(in_channels, out_channels, kernel_size):\n",
        "#     \"\"\"Make a 2D bilinear kernel suitable for upsampling\"\"\"\n",
        "#     factor = (kernel_size + 1) // 2\n",
        "#     if kernel_size % 2 == 1:\n",
        "#         center = factor - 1\n",
        "#     else:\n",
        "#         center = factor - 0.5\n",
        "#     og = np.ogrid[:kernel_size, :kernel_size]\n",
        "#     filt = (1 - abs(og[0] - center) / factor) * \\\n",
        "#            (1 - abs(og[1] - center) / factor)\n",
        "#     weight = np.zeros((in_channels, out_channels, kernel_size, kernel_size),\n",
        "#                       dtype=np.float64)\n",
        "#     weight[range(in_channels), range(out_channels), :, :] = filt\n",
        "#     return torch.from_numpy(weight).float()\n",
        "# class MyModel(nn.Module):\n",
        "\n",
        "#     def __init__(self, n_class = 9): # feel free to modify input paramters\n",
        "#         super(MyModel, self).__init__()\n",
        "#         # conv1\n",
        "#         self.conv1_1 = nn.Conv2d(3, 64, 3, padding=100)\n",
        "#         self.relu1_1 = nn.ReLU(inplace=True)\n",
        "#         self.conv1_2 = nn.Conv2d(64, 64, 3, padding=1)\n",
        "#         self.relu1_2 = nn.ReLU(inplace=True)\n",
        "#         self.pool1 = nn.MaxPool2d(2, stride=2, ceil_mode=True)  # 1/2\n",
        "\n",
        "#         # conv2\n",
        "#         self.conv2_1 = nn.Conv2d(64, 128, 3, padding=1)\n",
        "#         self.relu2_1 = nn.ReLU(inplace=True)\n",
        "#         self.conv2_2 = nn.Conv2d(128, 128, 3, padding=1)\n",
        "#         self.relu2_2 = nn.ReLU(inplace=True)\n",
        "#         self.pool2 = nn.MaxPool2d(2, stride=2, ceil_mode=True)  # 1/4\n",
        "\n",
        "#         # conv3\n",
        "#         self.conv3_1 = nn.Conv2d(128, 256, 3, padding=1)\n",
        "#         self.relu3_1 = nn.ReLU(inplace=True)\n",
        "#         self.conv3_2 = nn.Conv2d(256, 256, 3, padding=1)\n",
        "#         self.relu3_2 = nn.ReLU(inplace=True)\n",
        "#         self.conv3_3 = nn.Conv2d(256, 256, 3, padding=1)\n",
        "#         self.relu3_3 = nn.ReLU(inplace=True)\n",
        "#         self.pool3 = nn.MaxPool2d(2, stride=2, ceil_mode=True)  # 1/8\n",
        "\n",
        "#         # conv4\n",
        "#         self.conv4_1 = nn.Conv2d(256, 512, 3, padding=1)\n",
        "#         self.relu4_1 = nn.ReLU(inplace=True)\n",
        "#         self.conv4_2 = nn.Conv2d(512, 512, 3, padding=1)\n",
        "#         self.relu4_2 = nn.ReLU(inplace=True)\n",
        "#         self.conv4_3 = nn.Conv2d(512, 512, 3, padding=1)\n",
        "#         self.relu4_3 = nn.ReLU(inplace=True)\n",
        "#         self.pool4 = nn.MaxPool2d(2, stride=2, ceil_mode=True)  # 1/16\n",
        "\n",
        "#         # conv5\n",
        "#         self.conv5_1 = nn.Conv2d(512, 512, 3, padding=1)\n",
        "#         self.relu5_1 = nn.ReLU(inplace=True)\n",
        "#         self.conv5_2 = nn.Conv2d(512, 512, 3, padding=1)\n",
        "#         self.relu5_2 = nn.ReLU(inplace=True)\n",
        "#         self.conv5_3 = nn.Conv2d(512, 512, 3, padding=1)\n",
        "#         self.relu5_3 = nn.ReLU(inplace=True)\n",
        "#         self.pool5 = nn.MaxPool2d(2, stride=2, ceil_mode=True)  # 1/32\n",
        "\n",
        "#         # fc6\n",
        "#         self.fc6 = nn.Conv2d(512, 4096, 7)\n",
        "#         self.relu6 = nn.ReLU(inplace=True)\n",
        "#         self.drop6 = nn.Dropout2d()\n",
        "\n",
        "#         # fc7\n",
        "#         self.fc7 = nn.Conv2d(4096, 4096, 1)\n",
        "#         self.relu7 = nn.ReLU(inplace=True)\n",
        "#         self.drop7 = nn.Dropout2d()\n",
        "\n",
        "#         self.score_fr = nn.Conv2d(4096, n_class, 1)\n",
        "#         self.upscore = nn.ConvTranspose2d(n_class, n_class, 64, stride=32,\n",
        "#                                           bias=False)\n",
        "#         self._initialize_weights()\n",
        "#     def _initialize_weights(self):\n",
        "#       for m in self.modules():\n",
        "#             if isinstance(m, nn.Conv2d):\n",
        "#                 m.weight.data.zero_()\n",
        "#                 if m.bias is not None:\n",
        "#                     m.bias.data.zero_()\n",
        "#             if isinstance(m, nn.ConvTranspose2d):\n",
        "#                 assert m.kernel_size[0] == m.kernel_size[1]\n",
        "#                 initial_weight = get_upsampling_weight(\n",
        "#                     m.in_channels, m.out_channels, m.kernel_size[0])\n",
        "#                 m.weight.data.copy_(initial_weight)   \n",
        "#     def forward(self, x):\n",
        "#         h = x\n",
        "#         h = self.relu1_1(self.conv1_1(h))\n",
        "#         h = self.relu1_2(self.conv1_2(h))\n",
        "#         h = self.pool1(h)\n",
        "\n",
        "#         h = self.relu2_1(self.conv2_1(h))\n",
        "#         h = self.relu2_2(self.conv2_2(h))\n",
        "#         h = self.pool2(h)\n",
        "\n",
        "#         h = self.relu3_1(self.conv3_1(h))\n",
        "#         h = self.relu3_2(self.conv3_2(h))\n",
        "#         h = self.relu3_3(self.conv3_3(h))\n",
        "#         h = self.pool3(h)\n",
        "\n",
        "#         h = self.relu4_1(self.conv4_1(h))\n",
        "#         h = self.relu4_2(self.conv4_2(h))\n",
        "#         h = self.relu4_3(self.conv4_3(h))\n",
        "#         h = self.pool4(h)\n",
        "\n",
        "#         h = self.relu5_1(self.conv5_1(h))\n",
        "#         h = self.relu5_2(self.conv5_2(h))\n",
        "#         h = self.relu5_3(self.conv5_3(h))\n",
        "#         h = self.pool5(h)\n",
        "#         #print(h.shape)\n",
        "#         h = self.relu6(self.fc6(h))\n",
        "#         h = self.drop6(h)\n",
        "\n",
        "#         h = self.relu7(self.fc7(h))\n",
        "#         h = self.drop7(h)\n",
        "\n",
        "#         h = self.score_fr(h)\n",
        "\n",
        "#         h = self.upscore(h)\n",
        "#         #print(\"upscore\",h.shape)\n",
        "#         h = h[:, :, 19:19 + x.size()[2], 19:19 + x.size()[3]].contiguous()\n",
        "#         #print(\"h\",h.shape)\n",
        "#         return h"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xz6pBQNdaCaM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class Conv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.conv_block = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(mid_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv_block(x)\n",
        "\n",
        "class downsample(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.maxpool_conv = nn.Sequential(\n",
        "            nn.MaxPool2d(2),\n",
        "            Conv(in_channels, out_channels)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.maxpool_conv(x)\n",
        "\n",
        "\n",
        "class upsample(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
        "        self.conv = Conv(in_channels, out_channels, in_channels // 2)\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        x1 = self.up(x1)\n",
        "        diffY = x2.size()[2] - x1.size()[2]\n",
        "        diffX = x2.size()[3] - x1.size()[3]\n",
        "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
        "                        diffY // 2, diffY - diffY // 2])\n",
        "        x = torch.cat([x2, x1], dim=1)\n",
        "        return self.conv(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_FZInxdQX8Me",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " class MyModel(nn.Module):\n",
        "\n",
        "    def __init__(self, n_class = 9, n_channel = 3): # feel free to modify input paramters\n",
        "        super(MyModel, self).__init__()\n",
        "        self.conv1 = Conv(n_channel, 64)\n",
        "        self.down1 = downsample(64, 128)\n",
        "        self.down2 = downsample(128, 256)\n",
        "        self.down3 = downsample(256, 512)\n",
        "        self.down4 = downsample(512, 512)\n",
        "        self.up1 = upsample(1024, 256, True)\n",
        "        self.up2 = upsample(512, 128, True)\n",
        "        self.up3 = upsample(256, 64, True)\n",
        "        self.up4 = upsample(128, 64, True)\n",
        "        self.conv2 = nn.Conv2d(64, n_class, kernel_size=1) \n",
        "    def forward(self, x):\n",
        "        h1 = self.conv1(x)\n",
        "        h2 = self.down1(h1)\n",
        "        h3 = self.down2(h2)\n",
        "        h4 = self.down3(h3)\n",
        "        h5 = self.down4(h4)\n",
        "        print(h3.shape, h4.shape, h5.shape)\n",
        "        h = self.up1(h5, h4)\n",
        "        h = self.up2(h, h3)\n",
        "        h = self.up3(h, h2)\n",
        "        h = self.up4(h, h1)\n",
        "        h = self.conv2(h)\n",
        "        return h"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hOI3XtwsJS7J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aeZky2AHeyec",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create an instance of the nn.module class defined above:\n",
        "net = MyModel()\n",
        "net = net.cuda() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "leO_j65YBQc9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchsummary import summary\n",
        "summary(net, (3,224,288))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v47VHZ49Xfuz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(net)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CiFQ8o39Cgr5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "\n",
        "\n",
        "# Tune the learning rate.\n",
        "# See whether the momentum is useful or not\n",
        "#optimizer = optim.SGD(net.parameters(), lr=0.005, momentum=0.9)\n",
        "\n",
        "\n",
        "w_decay    = 1e-5\n",
        "lr = 1e-4\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "#optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
        "optimizer = optim.Adam(net.parameters(), lr)\n",
        "# optimizer = optim.RMSprop(net.parameters(), lr=0.005, momentum=0, weight_decay=1e-4)\n",
        "\n",
        "train_loss_over_epochs = []\n",
        "aps_over_epochs = []\n",
        "ious_over_epochs = []\n",
        "# torch.cuda.empty_cache()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n8-XGqBVyEuF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O02dkBiDChTr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This is a trivial semantic segmentor. For eqch pixel location it computes the \n",
        "# distribution of the class label in the training set and uses that as the \n",
        "# prediction. Quite unsuprisingly it doesn't perform very well. Though we provide\n",
        "# this code so that you can understand the data formats for the benchmarking \n",
        "# functions.\n",
        "########################################################################\n",
        "# TODO: Implement your training cycles, make sure you evaluate on validation \n",
        "# dataset and compute evaluation metrics every so often. \n",
        "# You may also want to save models that perform well.\n",
        "\n",
        "EPOCHS = 20\n",
        "train_dataset = SegmentationDataset(split='train')\n",
        "train_dataloader = data.DataLoader(train_dataset, batch_size=8, \n",
        "                                       shuffle=True, num_workers=4, \n",
        "                                       drop_last=True)\n",
        "val_dataset = SegmentationDataset(split='val')\n",
        "val_dataloader = data.DataLoader(val_dataset, batch_size=8, \n",
        "                                       shuffle=True, num_workers=4, \n",
        "                                       drop_last=True)\n",
        "for epoch in tqdm(range(EPOCHS), total=EPOCHS):\n",
        "    running_loss = 0.0\n",
        "    net.train()\n",
        "    \n",
        "    for i, batch in enumerate(tqdm(train_dataloader)):\n",
        "      img, gt = batch\n",
        "      img = img.cuda()\n",
        "      gt = gt.cuda()\n",
        "      optimizer.zero_grad()\n",
        "      outputs = net(img)\n",
        "      #print(outputs.shape, gt.shape)\n",
        "      loss = criterion(outputs, gt[:,0])\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "        # print statistics\n",
        "      running_loss += loss.item()\n",
        "      break\n",
        "     # Normalizing the loss by the total number of train batches\n",
        "    running_loss/=len(train_dataloader)\n",
        "    print('[%d] loss: %.3f' %\n",
        "          (epoch + 1, running_loss))\n",
        "    with torch.no_grad():\n",
        "      net.eval()\n",
        "      gts, preds, classes = simple_predict('val', net)\n",
        "      aps, ious = segmentation_eval(gts, preds, classes, 'cs543-simple-val.pdf')\n",
        "    train_loss_over_epochs.append(running_loss)\n",
        "    aps_over_epochs.append(np.mean(aps))\n",
        "    ious_over_epochs.append(np.mean(ious))\n",
        "    \n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5A-_26lgurh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot train loss over epochs and val set accuracy over epochs\n",
        "# Nothing to change here\n",
        "# -------------\n",
        "plt.ioff()\n",
        "fig = plt.figure()\n",
        "# plt.ylabel('Train loss')\n",
        "# plt.xlabel('Epochs')\n",
        "# plt.plot(np.arange(EPOCHS), train_loss_over_epochs, 'k-')\n",
        "# plt.title('Train loss vs Epochs')\n",
        "# plt.xticks(np.arange(EPOCHS, dtype=int))\n",
        "# plt.grid(True)\n",
        "# plt.show()\n",
        "# plt.savefig(\"plot.png\")\n",
        "# plt.close(fig)\n",
        "\n",
        "# plt.subplot(2, 1, 2)\n",
        "# plt.plot(np.arange(EPOCHS), aps_over_epochs, 'b-')\n",
        "# plt.ylabel('mAP')\n",
        "# plt.xlabel('Epochs')\n",
        "# plt.xticks(np.arange(EPOCHS, dtype=int))\n",
        "# plt.grid(True)\n",
        "# plt.savefig(\"plot1.png\")\n",
        "# plt.close(fig)\n",
        "# print('Finished Training')\n",
        "\n",
        "# plt.subplot(2, 1, 2)\n",
        "plt.plot(np.arange(EPOCHS), ious_over_epochs, 'g-')\n",
        "plt.ylabel('mIOUs')\n",
        "plt.xlabel('Epochs')\n",
        "plt.xticks(np.arange(EPOCHS, dtype=int))\n",
        "plt.grid(True)\n",
        "plt.savefig(\"plot2.png\")\n",
        "plt.close(fig)\n",
        "# print('Finished Training')\n",
        "# # -------------"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UFRPEgNx_N8e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def simple_predict(split, model):\n",
        "    dataset = SegmentationDataset(split=split, data_dir=DATASET_PATH)\n",
        "    dataloader = data.DataLoader(dataset, batch_size=1, shuffle=False, \n",
        "                                 num_workers=0, drop_last=False)\n",
        "    gts, preds = [], []\n",
        "    for i, batch in enumerate(tqdm(dataloader)):\n",
        "      img, gt = batch\n",
        "      img = img.cuda()\n",
        "      gt = gt.cuda()\n",
        "      outputs = net(Variable(img))\n",
        "      outputs = F.softmax(outputs)\n",
        "      gts.append(gt.data.cpu().numpy())\n",
        "      preds.append(outputs[0].data.cpu().numpy())\n",
        "    gts = np.array(gts)\n",
        "    preds = np.array(preds)\n",
        "    return gts, preds, list(dataset.classes)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XcS71R0Mz37T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with torch.no_grad():\n",
        "      net.eval()\n",
        "      gts, preds, classes = simple_predict('test', net)\n",
        "      aps, ious = segmentation_eval(gts, preds, classes, 'cs543-simple-val.pdf')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HA9WZ-Nqh1Ka",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "########################################################################\n",
        "# TODO: Evaluate your result, and report Mean average precision on test dataset \n",
        "# using provided helper function. Here we show how we can train and evaluate the \n",
        "# simple model that we provided on the validation set. You will want to report\n",
        "# performance on the validation set for the variants you tried, and the \n",
        "# performance of the final model on the test set.\n",
        "gts, preds, classes = simple_predict('test', model)\n",
        "aps, ious = segmentation_eval(gts, preds, classes, 'cs543-simple-val.pdf')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H90RJn27ZDsc",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIbc275KW1Pf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(gts[0].shape,preds.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8x8s37SuBc6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.mean(ious)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0CzL1GK4fpy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}