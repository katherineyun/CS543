{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "part2.2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2uohksRc8R6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Mounting your Google Drive is optional, and you could also simply copy and\n",
        "# upload the data to your colab instance. This manula upload is also easy to do, \n",
        "# but you will have to figure out how to do it.\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLFBEMfVdHId",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.chdir(\"/content/\")\n",
        "# if not os.path.exists(\"/content/gdrive/My Drive/CS_543_MP4\"):\n",
        "#     os.makedirs(\"/content/gdrive/My Drive/CS_543_MP4\")\n",
        "\n",
        "# from google.colab import files\n",
        "# uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJhWxMTBj5qU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip data.zip -d data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "geohpotit_Ek"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UzpXeiVddIdi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import glob\n",
        "import os\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from tqdm.notebook import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, average_precision_score\n",
        "\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils import data\n",
        "from torchvision.transforms import ToTensor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTlJmzl7dR4_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DATASET_PATH = 'data/data/sbd/'\n",
        "\n",
        "class SegmentationDataset(data.Dataset):\n",
        "    \"\"\"\n",
        "    Data loader for the Segmentation Dataset. If data loading is a bottleneck, \n",
        "    you may want to optimize this in for faster training. Possibilities include\n",
        "    pre-loading all images and annotations into memory before training, so as \n",
        "    to limit delays due to disk reads.\n",
        "    \"\"\"\n",
        "    def __init__(self, split=\"train\", data_dir=DATASET_PATH):\n",
        "        assert(split in [\"train\", \"val\", \"test\"])\n",
        "        self.img_dir = os.path.join(data_dir, split)\n",
        "        self.classes = []\n",
        "        with open(os.path.join(data_dir, 'classes.txt'), 'r') as f:\n",
        "          for l in f:\n",
        "            self.classes.append(l.rstrip())\n",
        "        self.n_classes = len(self.classes)\n",
        "        self.split = split\n",
        "        self.data = glob.glob(self.img_dir + '/*.jpg') \n",
        "        self.data = [os.path.splitext(l)[0] for l in self.data]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img = Image.open(self.data[index] + '.jpg')\n",
        "        gt = Image.open(self.data[index] + '.png')\n",
        "        \n",
        "        img = ToTensor()(img)\n",
        "        gt = torch.LongTensor(np.asarray(gt)).unsqueeze(0)\n",
        "        return img, gt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6Dtn7yudjC8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def segmentation_eval(gts, preds, classes, plot_file_name):\n",
        "    \"\"\"\n",
        "    @param    gts               numpy.ndarray   ground truth labels\n",
        "    @param    preds             numpy.ndarray   predicted labels\n",
        "    @param    classes           string          class names\n",
        "    @param    plot_file_name    string          plot file names\n",
        "    \"\"\"\n",
        "    ious, counts = compute_confusion_matrix(gts, preds)\n",
        "    aps = compute_ap(gts, preds)\n",
        "    plot_results(counts, ious, aps, classes, plot_file_name)\n",
        "    for i in range(len(classes)):\n",
        "        print('{:>20s}: AP: {:0.2f}, IoU: {:0.2f}'.format(classes[i], aps[i], ious[i]))\n",
        "    print('{:>20s}: AP: {:0.2f}, IoU: {:0.2f}'.format('mean', np.mean(aps), np.mean(ious)))\n",
        "    return aps, ious\n",
        "\n",
        "def plot_results(counts, ious, aps, classes, file_name):\n",
        "    fig, ax = plt.subplots(1,1)\n",
        "    conf = counts / np.sum(counts, 1, keepdims=True)\n",
        "    conf = np.concatenate([conf, np.array(aps).reshape(-1,1), \n",
        "                           np.array(ious).reshape(-1,1)], 1)\n",
        "    conf = conf * 100.\n",
        "    sns.heatmap(conf, annot=True, ax=ax, fmt='3.0f') \n",
        "    arts = [] \n",
        "    # labels, title and ticks\n",
        "    _ = ax.set_xlabel('Predicted labels')\n",
        "    arts.append(_)\n",
        "    _ = ax.set_ylabel('True labels')\n",
        "    arts.append(_)\n",
        "    _ = ax.set_title('Confusion Matrix, mAP: {:5.1f}, mIoU: {:5.1f}'.format(\n",
        "      np.mean(aps)*100., np.mean(ious)*100.))\n",
        "    arts.append(_)\n",
        "    _ = ax.xaxis.set_ticklabels(classes + ['AP', 'IoU'], rotation=90)\n",
        "    arts.append(_)\n",
        "    _ = ax.yaxis.set_ticklabels(classes, rotation=0)\n",
        "    arts.append(_)\n",
        "    fig.savefig(file_name, bbox_inches='tight')\n",
        "\n",
        "def compute_ap(gts, preds):\n",
        "    aps = []\n",
        "    for i in range(preds.shape[1]):\n",
        "      ap, prec, rec = calc_pr(gts == i, preds[:,i:i+1,:,:])\n",
        "      aps.append(ap)\n",
        "    return aps\n",
        "\n",
        "def calc_pr(gt, out, wt=None):\n",
        "    gt = gt.astype(np.float64).reshape((-1,1))\n",
        "    out = out.astype(np.float64).reshape((-1,1))\n",
        "\n",
        "    tog = np.concatenate([gt, out], axis=1)*1.\n",
        "    ind = np.argsort(tog[:,1], axis=0)[::-1]\n",
        "    tog = tog[ind,:]\n",
        "    cumsumsortgt = np.cumsum(tog[:,0])\n",
        "    cumsumsortwt = np.cumsum(tog[:,0]-tog[:,0]+1)\n",
        "    prec = cumsumsortgt / cumsumsortwt\n",
        "    rec = cumsumsortgt / np.sum(tog[:,0])\n",
        "    ap = voc_ap(rec, prec)\n",
        "    return ap, rec, prec\n",
        "\n",
        "def voc_ap(rec, prec):\n",
        "    rec = rec.reshape((-1,1))\n",
        "    prec = prec.reshape((-1,1))\n",
        "    z = np.zeros((1,1)) \n",
        "    o = np.ones((1,1))\n",
        "    mrec = np.vstack((z, rec, o))\n",
        "    mpre = np.vstack((z, prec, z))\n",
        "\n",
        "    mpre = np.maximum.accumulate(mpre[::-1])[::-1]\n",
        "    I = np.where(mrec[1:] != mrec[0:-1])[0]+1;\n",
        "    ap = np.sum((mrec[I] - mrec[I-1])*mpre[I])\n",
        "    return ap\n",
        "\n",
        "def compute_confusion_matrix(gts, preds):\n",
        "    preds_cls = np.argmax(preds, 1)\n",
        "    gts = gts[:,0]\n",
        "    #print(gts.shape, preds.shape)\n",
        "    conf = confusion_matrix(gts.ravel(), preds_cls.ravel())\n",
        "    inter = np.diag(conf)\n",
        "    union = np.sum(conf, 0) + np.sum(conf, 1) - np.diag(conf)\n",
        "    union = np.maximum(union, 1)\n",
        "    return inter / union, conf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_FZInxdQX8Me",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyModel(nn.Module):\n",
        "\n",
        "    def __init__(self, n_class = 9, n_channel = 3, bilinear = True): # feel free to modify input paramters\n",
        "        super(MyModel, self).__init__()\n",
        "        self.resnet = models.resnet18(pretrained=True)\n",
        "        self.base = list(self.resnet.children())\n",
        "        self.layer0 = nn.Sequential(*self.base[:6])\n",
        "        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
        "        self.conv4 = nn.Conv2d(128, 64, 3, stride = 1, padding = 1)\n",
        "        self.norm4 = nn.BatchNorm2d(64)\n",
        "        self.conv5 = nn.Conv2d(64, n_class, 3, stride = 1, padding = 1)\n",
        "    def forward(self, x):\n",
        "        h = self.layer0(x)\n",
        "        #print(h.shape)\n",
        "        h = self.upsample(h)\n",
        "        #print(h.shape)\n",
        "        h = self.upsample(h)\n",
        "        #print(h.shape)\n",
        "        h = self.upsample(h)\n",
        "        h = self.conv4(h)\n",
        "        h = self.norm4(h)\n",
        "        h = self.conv5(h)\n",
        "        #print(h.shape)\n",
        "        return h"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hOI3XtwsJS7J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aeZky2AHeyec",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create an instance of the nn.module class defined above:\n",
        "net = MyModel()\n",
        "net = net.cuda() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pCaqh7RaDfxU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchsummary import summary\n",
        "summary(net, (3,224,288))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v47VHZ49Xfuz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(net)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CiFQ8o39Cgr5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "\n",
        "\n",
        "# Tune the learning rate.\n",
        "# See whether the momentum is useful or not\n",
        "#optimizer = optim.SGD(net.parameters(), lr=0.005, momentum=0.9)\n",
        "\n",
        "\n",
        "w_decay    = 1e-5\n",
        "lr = 1e-4\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "#optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
        "optimizer = optim.Adam(net.parameters(), lr)\n",
        "# optimizer = optim.RMSprop(net.parameters(), lr=0.005, momentum=0, weight_decay=1e-4)\n",
        "\n",
        "train_loss_over_epochs = []\n",
        "aps_over_epochs = []\n",
        "ious_over_epochs = []\n",
        "# torch.cuda.empty_cache()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O02dkBiDChTr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This is a trivial semantic segmentor. For eqch pixel location it computes the \n",
        "# distribution of the class label in the training set and uses that as the \n",
        "# prediction. Quite unsuprisingly it doesn't perform very well. Though we provide\n",
        "# this code so that you can understand the data formats for the benchmarking \n",
        "# functions.\n",
        "########################################################################\n",
        "# TODO: Implement your training cycles, make sure you evaluate on validation \n",
        "# dataset and compute evaluation metrics every so often. \n",
        "# You may also want to save models that perform well.\n",
        "\n",
        "EPOCHS = 20\n",
        "train_dataset = SegmentationDataset(split='train')\n",
        "train_dataloader = data.DataLoader(train_dataset, batch_size=8, \n",
        "                                       shuffle=True, num_workers=4, \n",
        "                                       drop_last=True)\n",
        "val_dataset = SegmentationDataset(split='val')\n",
        "val_dataloader = data.DataLoader(val_dataset, batch_size=8, \n",
        "                                       shuffle=True, num_workers=4, \n",
        "                                       drop_last=True)\n",
        "for epoch in tqdm(range(EPOCHS), total=EPOCHS):\n",
        "    running_loss = 0.0\n",
        "    net.train()\n",
        "    \n",
        "    for i, batch in enumerate(tqdm(train_dataloader)):\n",
        "      img, gt = batch\n",
        "      img = img.cuda()\n",
        "      gt = gt.cuda()\n",
        "      optimizer.zero_grad()\n",
        "      outputs = net(img)\n",
        "      #print(outputs.shape, gt.shape)\n",
        "      loss = criterion(outputs, gt[:,0])\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "        # print statistics\n",
        "      running_loss += loss.item()\n",
        "      \n",
        "     # Normalizing the loss by the total number of train batches\n",
        "    running_loss/=len(train_dataloader)\n",
        "    print('[%d] loss: %.3f' %\n",
        "          (epoch + 1, running_loss))\n",
        "    with torch.no_grad():\n",
        "      net.eval()\n",
        "      gts, preds, classes = simple_predict('val', net)\n",
        "      aps, ious = segmentation_eval(gts, preds, classes, 'cs543-simple-val.pdf')\n",
        "    train_loss_over_epochs.append(running_loss)\n",
        "    aps_over_epochs.append(np.mean(aps))\n",
        "    ious_over_epochs.append(np.mean(ious))\n",
        "    \n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5A-_26lgurh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot train loss over epochs and val set accuracy over epochs\n",
        "# Nothing to change here\n",
        "# -------------\n",
        "plt.ioff()\n",
        "fig = plt.figure()\n",
        "plt.ylabel('Train loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.plot(np.arange(EPOCHS), train_loss_over_epochs, 'k-')\n",
        "plt.title('Train loss vs Epochs')\n",
        "plt.xticks(np.arange(EPOCHS, dtype=int))\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "# plt.savefig(\"plot.png\")\n",
        "# plt.close(fig)\n",
        "\n",
        "# plt.subplot(2, 1, 2)\n",
        "# plt.plot(np.arange(EPOCHS), aps_over_epochs, 'b-')\n",
        "# plt.ylabel('mAP')\n",
        "# plt.xlabel('Epochs')\n",
        "# plt.xticks(np.arange(EPOCHS, dtype=int))\n",
        "# plt.grid(True)\n",
        "# plt.savefig(\"plot1.png\")\n",
        "# plt.close(fig)\n",
        "# print('Finished Training')\n",
        "\n",
        "# plt.subplot(2, 1, 2)\n",
        "# plt.plot(np.arange(EPOCHS), ious_over_epochs, 'g-')\n",
        "# plt.ylabel('mIOUs')\n",
        "# plt.xlabel('Epochs')\n",
        "# plt.xticks(np.arange(EPOCHS, dtype=int))\n",
        "# plt.grid(True)\n",
        "# plt.savefig(\"plot2.png\")\n",
        "# plt.close(fig)\n",
        "# print('Finished Training')\n",
        "# # -------------"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UFRPEgNx_N8e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def simple_predict(split, model):\n",
        "    dataset = SegmentationDataset(split=split, data_dir=DATASET_PATH)\n",
        "    dataloader = data.DataLoader(dataset, batch_size=1, shuffle=False, \n",
        "                                 num_workers=0, drop_last=False)\n",
        "    gts, preds = [], []\n",
        "    for i, batch in enumerate(tqdm(dataloader)):\n",
        "      img, gt = batch\n",
        "      print(img.shape)\n",
        "      img = img.cuda()\n",
        "      gt = gt.cuda()\n",
        "      outputs = net(Variable(img))\n",
        "      outputs = F.softmax(outputs)\n",
        "      gts.append(gt.data.cpu().numpy())\n",
        "      preds.append(outputs[0].data.cpu().numpy())\n",
        "    gts = np.array(gts)\n",
        "    preds = np.array(preds)\n",
        "    return gts, preds, list(dataset.classes)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XcS71R0Mz37T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with torch.no_grad():\n",
        "      net.eval()\n",
        "      gts, preds, classes = simple_predict('test', net)\n",
        "      aps, ious = segmentation_eval(gts, preds, classes, 'cs543-simple-val.pdf')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HA9WZ-Nqh1Ka",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "########################################################################\n",
        "# TODO: Evaluate your result, and report Mean average precision on test dataset \n",
        "# using provided helper function. Here we show how we can train and evaluate the \n",
        "# simple model that we provided on the validation set. You will want to report\n",
        "# performance on the validation set for the variants you tried, and the \n",
        "# performance of the final model on the test set.\n",
        "\n",
        "gts, preds, classes = simple_predict('test', model)\n",
        "aps, ious = segmentation_eval(gts, preds, classes, 'cs543-simple-val.pdf')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H90RJn27ZDsc",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIbc275KW1Pf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(gts[0].shape,preds.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8x8s37SuBc6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.mean(ious)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0CzL1GK4fpy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}